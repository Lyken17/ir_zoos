fn (%input0: Tensor[(2, 1, 32, 32), float32], %label0: Tensor[(2, 10), float32], %v0_weight: Tensor[(6, 1, 7, 7), float32], %v0_bias: Tensor[(6), float32], %v2_weight: Tensor[(12, 6, 5, 5), float32], %v2_bias: Tensor[(12), float32], %v5_weight: Tensor[(80, 108), float32], %v5_bias: Tensor[(80), float32], %v7_weight: Tensor[(10, 80), float32], %v7_bias: Tensor[(10), float32]) {
  %0 = nn.conv2d(%input0, %v0_weight, strides=[3, 3], padding=[0, 0, 0, 0], channels=6, kernel_size=[7, 7]);
  %1 = nn.bias_add(%0, %v0_bias);
  %2 = nn.relu(%1);
  %3 = nn.conv2d(%2, %v2_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=12, kernel_size=[5, 5]);
  %4 = nn.bias_add(%3, %v2_bias);
  %5 = nn.relu(%4);
  %6 = reshape(%5, newshape=[0, -1, 1, 1]);
  %7 = squeeze(%6, axis=[2, 3]);
  %8 = nn.dense(%7, %v5_weight, units=None);
  %9 = nn.bias_add(%8, %v5_bias, axis=-1);
  %10 = nn.relu(%9);
  %11 = nn.dense(%10, %v7_weight, units=None);
  %12 = nn.bias_add(%11, %v7_bias, axis=-1);
  %13 = nn.log_softmax(%12);
  nn.cross_entropy_with_logits(%13, %label0)
}