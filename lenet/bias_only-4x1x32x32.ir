fn (%input0: Tensor[(4, 1, 32, 32), float32], %v0_weight: Tensor[(6, 1, 7, 7), float32], %v0_bias: Tensor[(6), float32], %v2_weight: Tensor[(12, 6, 5, 5), float32], %v2_bias: Tensor[(12), float32], %v5_weight: Tensor[(80, 108), float32], %v5_bias: Tensor[(80), float32], %v7_weight: Tensor[(10, 80), float32], %v7_bias: Tensor[(10), float32], %label0: Tensor[(4, 10), float32]) -> (float32, Tensor[(10), float32], Tensor[(10, 80), float32], Tensor[(80), float32], Tensor[(12), float32], Tensor[(6), float32]) {
  %0 = nn.conv2d(%input0, %v0_weight, strides=[3, 3], padding=[0, 0, 0, 0], channels=6, kernel_size=[7, 7]) /* ty=Tensor[(4, 6, 9, 9), float32] */;
  %1 = nn.bias_add(%0, %v0_bias) /* ty=Tensor[(4, 6, 9, 9), float32] */;
  %2 = nn.relu(%1) /* ty=Tensor[(4, 6, 9, 9), float32] */;
  %3 = nn.conv2d(%2, %v2_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=12, kernel_size=[5, 5]) /* ty=Tensor[(4, 12, 3, 3), float32] */;
  %4 = nn.bias_add(%3, %v2_bias) /* ty=Tensor[(4, 12, 3, 3), float32] */;
  %5 = nn.relu(%4) /* ty=Tensor[(4, 12, 3, 3), float32] */;
  %6 = reshape(%5, newshape=[0, -1, 1, 1]) /* ty=Tensor[(4, 108, 1, 1), float32] */;
  %7 = squeeze(%6, axis=[2, 3]) /* ty=Tensor[(4, 108), float32] */;
  %8 = nn.dense(%7, %v5_weight, units=None) /* ty=Tensor[(4, 80), float32] */;
  %9 = nn.bias_add(%8, %v5_bias, axis=-1) /* ty=Tensor[(4, 80), float32] */;
  %10 = nn.relu(%9) /* ty=Tensor[(4, 80), float32] */;
  %11 = nn.dense(%10, %v7_weight, units=None) /* ty=Tensor[(4, 10), float32] */;
  %12 = nn.bias_add(%11, %v7_bias, axis=-1) /* ty=Tensor[(4, 10), float32] */;
  %13 = nn.log_softmax(%12) /* ty=Tensor[(4, 10), float32] */;
  %14 = nn.cross_entropy_with_logits(%13, %label0) /* ty=float32 */;
  %15 = ones_like(%14) /* ty=float32 */;
  %16 = cast(4 /* ty=int32 */, dtype="float32") /* ty=float32 */;
  %17 = divide(%15, %16) /* ty=float32 */;
  %18 = negative(%17) /* ty=float32 */;
  %19 = multiply(%18, %label0) /* ty=Tensor[(4, 10), float32] */;
  %20 = sum(%19, axis=[-1], keepdims=True) /* ty=Tensor[(4, 1), float32] */;
  %21 = exp(%13) /* ty=Tensor[(4, 10), float32] */;
  %22 = multiply(%20, %21) /* ty=Tensor[(4, 10), float32] */;
  %23 = subtract(%19, %22) /* ty=Tensor[(4, 10), float32] */;
  %24 = transpose(%23, axes=None) /* ty=Tensor[(10, 4), float32] */;
  %25 = zeros_like(%9) /* ty=Tensor[(4, 80), float32] */;
  %26 = less(%9, %25) /* ty=Tensor[(4, 80), bool] */;
  %27 = nn.matmul(%23, %v7_weight, units=None) /* ty=Tensor[(4, 80), float32] */;
  %28 = where(%26, %25, %27) /* ty=Tensor[(4, 80), float32] */;
  %29 = zeros_like(%4) /* ty=Tensor[(4, 12, 3, 3), float32] */;
  %30 = nn.matmul(%28, %v5_weight, units=None) /* ty=Tensor[(4, 108), float32] */;
  %31 = reshape_like(%30, %6) /* ty=Tensor[(4, 108, 1, 1), float32] */;
  %32 = less(%4, %29) /* ty=Tensor[(4, 12, 3, 3), bool] */;
  %33 = reshape_like(%31, %5) /* ty=Tensor[(4, 12, 3, 3), float32] */;
  %34 = where(%32, %29, %33) /* ty=Tensor[(4, 12, 3, 3), float32] */;
  %35 = zeros_like(%1) /* ty=Tensor[(4, 6, 9, 9), float32] */;
  %36 = less(%1, %35) /* ty=Tensor[(4, 6, 9, 9), bool] */;
  %37 = nn.conv2d_transpose(%34, %v2_weight, channels=6, kernel_size=[5, 5], strides=[2, 2], padding=[0, 0, 0, 0], kernel_layout="IOHW") /* ty=Tensor[(4, 6, 9, 9), float32] */;
  %38 = where(%36, %35, %37) /* ty=Tensor[(4, 6, 9, 9), float32] */;
  %39 = sum(%23, axis=[-1], exclude=True) /* ty=Tensor[(10), float32] */;
  %40 = nn.matmul(%24, %10, units=None) /* ty=Tensor[(10, 80), float32] */;
  %41 = sum(%28, axis=[-1], exclude=True) /* ty=Tensor[(80), float32] */;
  %42 = sum(%34, axis=[1], exclude=True) /* ty=Tensor[(12), float32] */;
  %43 = sum(%38, axis=[1], exclude=True) /* ty=Tensor[(6), float32] */;
  (%14, %39, %40, %41, %42, %43)
}