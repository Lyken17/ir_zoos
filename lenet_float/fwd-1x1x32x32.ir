fn (%input: Tensor[(1, 1, 32, 32), float32], %label: Tensor[(1, 10), float32], %conv1_weight: Tensor[(6, 1, 5, 5), float32], %conv1_bias: Tensor[(6), float32], %conv2_weight: Tensor[(16, 6, 5, 5), float32], %conv2_bias: Tensor[(16), float32], %fc1_weight: Tensor[(120, 400), float32], %fc1_bias: Tensor[(120), float32], %fc2_weight: Tensor[(84, 120), float32], %fc2_bias: Tensor[(84), float32], %fc3_weight: Tensor[(10, 84), float32], %fc3_bias: Tensor[(10), float32]) -> float32 {
  %0 = nn.conv2d(%input, %conv1_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=6, kernel_size=[5, 5]) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %1 = nn.bias_add(%0, %conv1_bias) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %2 = nn.relu(%1) /* ty=Tensor[(1, 6, 14, 14), float32] */;
  %3 = nn.conv2d(%2, %conv2_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=16, kernel_size=[5, 5]) /* ty=Tensor[(1, 16, 5, 5), float32] */;
  %4 = nn.bias_add(%3, %conv2_bias) /* ty=Tensor[(1, 16, 5, 5), float32] */;
  %5 = nn.relu(%4) /* ty=Tensor[(1, 16, 5, 5), float32] */;
  %6 = reshape(%5, newshape=[0, -1, 1, 1]) /* ty=Tensor[(1, 400, 1, 1), float32] */;
  %7 = squeeze(%6, axis=[2, 3]) /* ty=Tensor[(1, 400), float32] */;
  %8 = nn.dense(%7, %fc1_weight, units=None) /* ty=Tensor[(1, 120), float32] */;
  %9 = nn.bias_add(%8, %fc1_bias, axis=-1) /* ty=Tensor[(1, 120), float32] */;
  %10 = nn.relu(%9) /* ty=Tensor[(1, 120), float32] */;
  %11 = nn.dense(%10, %fc2_weight, units=None) /* ty=Tensor[(1, 84), float32] */;
  %12 = nn.bias_add(%11, %fc2_bias, axis=-1) /* ty=Tensor[(1, 84), float32] */;
  %13 = nn.relu(%12) /* ty=Tensor[(1, 84), float32] */;
  %14 = nn.dense(%13, %fc3_weight, units=None) /* ty=Tensor[(1, 10), float32] */;
  %15 = nn.bias_add(%14, %fc3_bias, axis=-1) /* ty=Tensor[(1, 10), float32] */;
  %16 = nn.log_softmax(%15) /* ty=Tensor[(1, 10), float32] */;
  nn.cross_entropy_with_logits(%16, %label) /* ty=float32 */
}